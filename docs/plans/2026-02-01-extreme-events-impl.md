# æç«¯äº‹ä»¶å†å²å‚è€ƒåŠŸèƒ½ - å®ç°è®¡åˆ’

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** å½“ P90+ æç«¯å€¼å‡ºç°æ—¶ï¼Œæ˜¾ç¤ºå†å²ç»Ÿè®¡å’Œæœ€è¿‘æ¡ˆä¾‹ï¼Œå¸®åŠ©ç”¨æˆ·åˆ¤æ–­æ˜¯é¡¶/åº•è¿˜æ˜¯ä¸­ç»§ã€‚

**Architecture:** æ–°å¢ `extreme_events` è¡¨å­˜å‚¨æç«¯äº‹ä»¶ï¼Œå®æ—¶æ£€æµ‹ P90+ å¹¶è®°å½•ï¼Œå®šæ—¶å›å¡«åç»­ä»·æ ¼ï¼ŒæŠ¥å‘Šä¸­é™„åŠ å†å²ç»Ÿè®¡ã€‚ä¸‰çª—å£ï¼ˆ7d/30d/90dï¼‰ç‹¬ç«‹è®¡ç®—ç™¾åˆ†ä½å’Œè§¦å‘ã€‚

**Tech Stack:** Python 3.14, aiosqlite, aiohttp (Binance API)

---

## Task 1: ExtremeEvent æ•°æ®æ¨¡å‹

**Files:**
- Modify: `src/storage/models.py`
- Test: `tests/storage/test_models.py`

**Step 1: Write the failing test**

åœ¨ `tests/storage/test_models.py` æœ«å°¾æ·»åŠ ï¼š

```python
def test_extreme_event_model():
    from src.storage.models import ExtremeEvent

    event = ExtremeEvent(
        id=None,
        symbol="BTC",
        dimension="flow_1h",
        window_days=30,
        triggered_at=1706600000000,
        value=47_700_000.0,
        percentile=92.5,
        price_at_trigger=82000.0,
        price_4h=None,
        price_12h=None,
        price_24h=None,
        price_48h=None,
    )
    assert event.symbol == "BTC"
    assert event.window_days == 30
    assert event.price_4h is None
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest tests/storage/test_models.py::test_extreme_event_model -v`
Expected: FAIL with "cannot import name 'ExtremeEvent'"

**Step 3: Write minimal implementation**

åœ¨ `src/storage/models.py` æœ«å°¾æ·»åŠ ï¼š

```python
@dataclass
class ExtremeEvent:
    id: int | None
    symbol: str                    # BTC / ETH
    dimension: str                 # flow_1h / oi_change_1h / funding_rate / ...
    window_days: int               # 7 / 30 / 90
    triggered_at: int              # è§¦å‘æ—¶é—´ (ms)
    value: float                   # è§¦å‘æ—¶çš„å€¼
    percentile: float              # ç™¾åˆ†ä½
    price_at_trigger: float        # è§¦å‘æ—¶ä»·æ ¼
    price_4h: float | None         # 4h åä»·æ ¼
    price_12h: float | None        # 12h åä»·æ ¼
    price_24h: float | None        # 24h åä»·æ ¼
    price_48h: float | None        # 48h åä»·æ ¼
```

**Step 4: Run test to verify it passes**

Run: `uv run pytest tests/storage/test_models.py::test_extreme_event_model -v`
Expected: PASS

**Step 5: Commit**

```bash
git add src/storage/models.py tests/storage/test_models.py
git commit -m "feat: æ·»åŠ  ExtremeEvent æ•°æ®æ¨¡å‹"
```

---

## Task 2: extreme_events è¡¨ CRUD

**Files:**
- Modify: `src/storage/database.py`
- Test: `tests/storage/test_database.py`

**Step 1: Write the failing tests**

åœ¨ `tests/storage/test_database.py` æœ«å°¾æ·»åŠ ï¼š

```python
async def test_extreme_events_table_created(db: Database):
    """éªŒè¯è¡¨åˆ›å»º"""
    assert db.conn is not None
    cursor = await db.conn.execute(
        "SELECT name FROM sqlite_master WHERE type='table' AND name='extreme_events'"
    )
    row = await cursor.fetchone()
    assert row is not None


async def test_insert_and_get_extreme_event(db: Database):
    from src.storage.models import ExtremeEvent

    event = ExtremeEvent(
        id=None,
        symbol="BTC",
        dimension="flow_1h",
        window_days=30,
        triggered_at=1706600000000,
        value=47_700_000.0,
        percentile=92.5,
        price_at_trigger=82000.0,
        price_4h=None,
        price_12h=None,
        price_24h=None,
        price_48h=None,
    )
    event_id = await db.insert_extreme_event(event)
    assert event_id > 0

    events = await db.get_extreme_events("BTC", "flow_1h", 30, limit=10)
    assert len(events) == 1
    assert events[0].percentile == 92.5


async def test_get_extreme_events_completed_only(db: Database):
    """åªè¿”å›æœ‰å®Œæ•´åç»­ä»·æ ¼çš„äº‹ä»¶"""
    from src.storage.models import ExtremeEvent

    # æ’å…¥ä¸€ä¸ªå®Œæ•´çš„äº‹ä»¶
    complete = ExtremeEvent(
        id=None,
        symbol="BTC",
        dimension="flow_1h",
        window_days=30,
        triggered_at=1706500000000,
        value=50_000_000.0,
        percentile=95.0,
        price_at_trigger=80000.0,
        price_4h=80500.0,
        price_12h=79000.0,
        price_24h=78000.0,
        price_48h=79500.0,
    )
    await db.insert_extreme_event(complete)

    # æ’å…¥ä¸€ä¸ªä¸å®Œæ•´çš„äº‹ä»¶
    incomplete = ExtremeEvent(
        id=None,
        symbol="BTC",
        dimension="flow_1h",
        window_days=30,
        triggered_at=1706600000000,
        value=47_700_000.0,
        percentile=92.5,
        price_at_trigger=82000.0,
        price_4h=None,
        price_12h=None,
        price_24h=None,
        price_48h=None,
    )
    await db.insert_extreme_event(incomplete)

    # è·å–å®Œæ•´äº‹ä»¶
    events = await db.get_extreme_events("BTC", "flow_1h", 30, completed_only=True)
    assert len(events) == 1
    assert events[0].price_48h == 79500.0


async def test_update_extreme_event_prices(db: Database):
    """æµ‹è¯•å›å¡«åç»­ä»·æ ¼"""
    from src.storage.models import ExtremeEvent

    event = ExtremeEvent(
        id=None,
        symbol="BTC",
        dimension="flow_1h",
        window_days=30,
        triggered_at=1706600000000,
        value=47_700_000.0,
        percentile=92.5,
        price_at_trigger=82000.0,
        price_4h=None,
        price_12h=None,
        price_24h=None,
        price_48h=None,
    )
    event_id = await db.insert_extreme_event(event)

    await db.update_extreme_event_price(event_id, "price_4h", 82500.0)

    events = await db.get_extreme_events("BTC", "flow_1h", 30)
    assert events[0].price_4h == 82500.0


async def test_get_pending_backfill_events(db: Database):
    """æµ‹è¯•è·å–å¾…å›å¡«äº‹ä»¶"""
    import time

    from src.storage.models import ExtremeEvent

    now = int(time.time() * 1000)

    # æ’å…¥ä¸€ä¸ª 5 å°æ—¶å‰çš„äº‹ä»¶ï¼ˆåº”è¯¥å›å¡« price_4hï¼‰
    old_event = ExtremeEvent(
        id=None,
        symbol="BTC",
        dimension="flow_1h",
        window_days=30,
        triggered_at=now - 5 * 3600 * 1000,
        value=47_700_000.0,
        percentile=92.5,
        price_at_trigger=82000.0,
        price_4h=None,
        price_12h=None,
        price_24h=None,
        price_48h=None,
    )
    await db.insert_extreme_event(old_event)

    pending = await db.get_pending_backfill_events()
    assert len(pending) >= 1
    assert any(e.price_4h is None for e in pending)


async def test_check_cooldown(db: Database):
    """æµ‹è¯•å†·å´æœŸæ£€æŸ¥"""
    import time

    from src.storage.models import ExtremeEvent

    now = int(time.time() * 1000)

    event = ExtremeEvent(
        id=None,
        symbol="BTC",
        dimension="flow_1h",
        window_days=30,
        triggered_at=now - 30 * 60 * 1000,  # 30 åˆ†é’Ÿå‰
        value=47_700_000.0,
        percentile=92.5,
        price_at_trigger=82000.0,
        price_4h=None,
        price_12h=None,
        price_24h=None,
        price_48h=None,
    )
    await db.insert_extreme_event(event)

    # å†·å´æœŸå†…
    in_cooldown = await db.is_in_cooldown("BTC", "flow_1h", 30, cooldown_hours=1)
    assert in_cooldown is True

    # ä¸åŒçª—å£ä¸å—å½±å“
    not_in_cooldown = await db.is_in_cooldown("BTC", "flow_1h", 7, cooldown_hours=1)
    assert not_in_cooldown is False
```

**Step 2: Run tests to verify they fail**

Run: `uv run pytest tests/storage/test_database.py::test_extreme_events_table_created -v`
Expected: FAIL with "no such table: extreme_events"

**Step 3: Write implementation**

åœ¨ `src/storage/database.py` çš„ `_create_tables` æ–¹æ³•ä¸­æ·»åŠ è¡¨å®šä¹‰ï¼Œåœ¨ç±»ä¸­æ·»åŠ  CRUD æ–¹æ³•ï¼š

```python
# åœ¨ _create_tables çš„ executescript ä¸­æ·»åŠ ï¼š
            CREATE TABLE IF NOT EXISTS extreme_events (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                symbol TEXT NOT NULL,
                dimension TEXT NOT NULL,
                window_days INTEGER NOT NULL,
                triggered_at INTEGER NOT NULL,
                value REAL NOT NULL,
                percentile REAL NOT NULL,
                price_at_trigger REAL NOT NULL,
                price_4h REAL,
                price_12h REAL,
                price_24h REAL,
                price_48h REAL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            CREATE INDEX IF NOT EXISTS idx_extreme_events_lookup
                ON extreme_events(symbol, dimension, window_days, triggered_at);
```

åœ¨ `Database` ç±»æœ«å°¾æ·»åŠ æ–¹æ³•ï¼š

```python
    async def insert_extreme_event(self, event: "ExtremeEvent") -> int:
        from .models import ExtremeEvent  # noqa: F811

        assert self.conn is not None
        cursor = await self.conn.execute(
            """INSERT INTO extreme_events
               (symbol, dimension, window_days, triggered_at, value, percentile,
                price_at_trigger, price_4h, price_12h, price_24h, price_48h)
               VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
            (
                event.symbol,
                event.dimension,
                event.window_days,
                event.triggered_at,
                event.value,
                event.percentile,
                event.price_at_trigger,
                event.price_4h,
                event.price_12h,
                event.price_24h,
                event.price_48h,
            ),
        )
        await self.conn.commit()
        return cursor.lastrowid or 0

    async def get_extreme_events(
        self,
        symbol: str,
        dimension: str,
        window_days: int,
        limit: int = 20,
        completed_only: bool = False,
    ) -> list["ExtremeEvent"]:
        from .models import ExtremeEvent

        assert self.conn is not None
        query = """SELECT id, symbol, dimension, window_days, triggered_at, value,
                          percentile, price_at_trigger, price_4h, price_12h, price_24h, price_48h
                   FROM extreme_events
                   WHERE symbol = ? AND dimension = ? AND window_days = ?"""
        if completed_only:
            query += " AND price_48h IS NOT NULL"
        query += " ORDER BY triggered_at DESC LIMIT ?"
        cursor = await self.conn.execute(query, (symbol, dimension, window_days, limit))
        rows = await cursor.fetchall()
        return [ExtremeEvent(*row) for row in rows]

    async def update_extreme_event_price(
        self, event_id: int, price_field: str, price: float
    ) -> None:
        assert self.conn is not None
        valid_fields = {"price_4h", "price_12h", "price_24h", "price_48h"}
        if price_field not in valid_fields:
            raise ValueError(f"Invalid price field: {price_field}")
        await self.conn.execute(
            f"UPDATE extreme_events SET {price_field} = ? WHERE id = ?",
            (price, event_id),
        )
        await self.conn.commit()

    async def get_pending_backfill_events(self) -> list["ExtremeEvent"]:
        """è·å–éœ€è¦å›å¡«åç»­ä»·æ ¼çš„äº‹ä»¶"""
        from .models import ExtremeEvent

        assert self.conn is not None
        now = int(time.time() * 1000)
        cursor = await self.conn.execute(
            """SELECT id, symbol, dimension, window_days, triggered_at, value,
                      percentile, price_at_trigger, price_4h, price_12h, price_24h, price_48h
               FROM extreme_events
               WHERE (price_4h IS NULL AND triggered_at <= ?)
                  OR (price_12h IS NULL AND triggered_at <= ?)
                  OR (price_24h IS NULL AND triggered_at <= ?)
                  OR (price_48h IS NULL AND triggered_at <= ?)
               ORDER BY triggered_at ASC""",
            (
                now - 4 * 3600 * 1000,
                now - 12 * 3600 * 1000,
                now - 24 * 3600 * 1000,
                now - 48 * 3600 * 1000,
            ),
        )
        rows = await cursor.fetchall()
        return [ExtremeEvent(*row) for row in rows]

    async def is_in_cooldown(
        self,
        symbol: str,
        dimension: str,
        window_days: int,
        cooldown_hours: int = 1,
    ) -> bool:
        """æ£€æŸ¥æ˜¯å¦åœ¨å†·å´æœŸå†…"""
        assert self.conn is not None
        cutoff = int(time.time() * 1000) - cooldown_hours * 3600 * 1000
        cursor = await self.conn.execute(
            """SELECT 1 FROM extreme_events
               WHERE symbol = ? AND dimension = ? AND window_days = ? AND triggered_at > ?
               LIMIT 1""",
            (symbol, dimension, window_days, cutoff),
        )
        row = await cursor.fetchone()
        return row is not None
```

**Step 4: Run all tests to verify they pass**

Run: `uv run pytest tests/storage/test_database.py -v -k extreme`
Expected: All 6 extreme_events tests PASS

**Step 5: Commit**

```bash
git add src/storage/database.py tests/storage/test_database.py
git commit -m "feat: æ·»åŠ  extreme_events è¡¨å’Œ CRUD æ“ä½œ"
```

---

## Task 3: å¤šçª—å£ç™¾åˆ†ä½è®¡ç®—

**Files:**
- Modify: `src/aggregator/percentile.py`
- Test: `tests/aggregator/test_percentile.py`

**Step 1: Write the failing tests**

åœ¨ `tests/aggregator/test_percentile.py` æœ«å°¾æ·»åŠ ï¼š

```python
def test_calculate_percentile_multi_window():
    from src.aggregator.percentile import calculate_percentile_multi_window

    # æ¨¡æ‹Ÿ 30 å¤©æ•°æ®ï¼Œæ¯å¤©ä¸€ä¸ªå€¼
    history = list(range(10, 310, 10))  # 10, 20, ..., 300

    result = calculate_percentile_multi_window(
        value=250.0,
        history=history,
        windows=[7, 30],
    )
    assert "7d" in result
    assert "30d" in result
    # 7d: æœ€å 7 ä¸ªå€¼æ˜¯ 240, 250, 260, 270, 280, 290, 300
    # 250 æ¯” 240 å¤§ï¼Œæ‰€ä»¥ percentile = 1/7 * 100 = 14.3
    assert result["7d"] == pytest.approx(14.3, abs=0.1)
    # 30d: æœ€å 30 ä¸ªå€¼æ˜¯ 10, 20, ..., 300
    # 250 æ¯” 240 ä¸ªå€¼å¤§ï¼ˆ10-240ï¼‰ï¼Œæ‰€ä»¥ percentile = 24/30 * 100 = 80
    assert result["30d"] == pytest.approx(80.0, abs=0.1)


def test_calculate_percentile_multi_window_short_history():
    from src.aggregator.percentile import calculate_percentile_multi_window

    # åªæœ‰ 10 å¤©æ•°æ®
    history = list(range(10, 110, 10))  # 10, 20, ..., 100

    result = calculate_percentile_multi_window(
        value=75.0,
        history=history,
        windows=[7, 30, 90],
    )
    # 7d æ­£å¸¸è®¡ç®—
    assert "7d" in result
    # 30d å’Œ 90d æ•°æ®ä¸è¶³ï¼Œè¿”å› None
    assert result.get("30d") is None
    assert result.get("90d") is None


def test_format_multi_window_percentile():
    from src.aggregator.percentile import format_multi_window_percentile

    percentiles = {"7d": 92.5, "30d": 85.0, "90d": 70.0}
    result = format_multi_window_percentile(percentiles)
    assert "P93(7d)" in result or "P92(7d)" in result  # å››èˆäº”å…¥
    assert "P85(30d)" in result
    assert "P70(90d)" in result
```

**Step 2: Run tests to verify they fail**

Run: `uv run pytest tests/aggregator/test_percentile.py::test_calculate_percentile_multi_window -v`
Expected: FAIL with "cannot import name 'calculate_percentile_multi_window'"

**Step 3: Write implementation**

åœ¨ `src/aggregator/percentile.py` æœ«å°¾æ·»åŠ ï¼š

```python
def calculate_percentile_multi_window(
    value: float,
    history: list[float],
    windows: list[int] = [7, 30, 90],
) -> dict[str, float | None]:
    """
    è®¡ç®—å¤šçª—å£ç™¾åˆ†ä½

    Args:
        value: å½“å‰å€¼
        history: å†å²æ•°æ®åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´é¡ºåºï¼Œæ¯å¤©ä¸€ä¸ªå€¼ï¼‰
        windows: çª—å£å¤§å°åˆ—è¡¨ï¼ˆå¤©ï¼‰

    Returns:
        {çª—å£å: ç™¾åˆ†ä½} å­—å…¸ï¼Œæ•°æ®ä¸è¶³æ—¶ä¸º None
    """
    result: dict[str, float | None] = {}
    for window in windows:
        key = f"{window}d"
        if len(history) < window:
            result[key] = None
        else:
            window_data = history[-window:]
            result[key] = calculate_percentile(value, window_data)
    return result


def format_multi_window_percentile(percentiles: dict[str, float | None]) -> str:
    """æ ¼å¼åŒ–å¤šçª—å£ç™¾åˆ†ä½æ˜¾ç¤º"""
    parts = []
    for key in ["7d", "30d", "90d"]:
        pct = percentiles.get(key)
        if pct is not None:
            parts.append(f"P{int(round(pct))}({key})")
    return " / ".join(parts)
```

**Step 4: Run tests to verify they pass**

Run: `uv run pytest tests/aggregator/test_percentile.py -v`
Expected: All tests PASS

**Step 5: Commit**

```bash
git add src/aggregator/percentile.py tests/aggregator/test_percentile.py
git commit -m "feat: æ·»åŠ å¤šçª—å£ç™¾åˆ†ä½è®¡ç®—"
```

---

## Task 4: æç«¯äº‹ä»¶æ£€æµ‹ä¸è®°å½•

**Files:**
- Create: `src/aggregator/extreme_tracker.py`
- Create: `tests/aggregator/test_extreme_tracker.py`

**Step 1: Write the failing tests**

åˆ›å»º `tests/aggregator/test_extreme_tracker.py`ï¼š

```python
# tests/aggregator/test_extreme_tracker.py
import pytest

from src.aggregator.extreme_tracker import ExtremeTracker


@pytest.fixture
async def db(tmp_path):
    from src.storage.database import Database

    db_path = tmp_path / "test.db"
    database = Database(str(db_path))
    await database.init()
    yield database
    await database.close()


async def test_detect_extreme_single_window(db):
    tracker = ExtremeTracker(db)

    # æ¨¡æ‹Ÿ 7 å¤©å†å²æ•°æ®
    history = [10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0]
    current_value = 95.0  # è¶…è¿‡æ‰€æœ‰å†å²å€¼

    extremes = tracker.detect_extremes(
        value=current_value,
        history=history,
        threshold=90,
    )

    assert "7d" in extremes
    assert extremes["7d"] == 100.0  # è¶…è¿‡æ‰€æœ‰å€¼


async def test_record_extreme_event(db):
    import time

    tracker = ExtremeTracker(db)

    await tracker.record_event(
        symbol="BTC",
        dimension="flow_1h",
        window_days=30,
        value=47_700_000.0,
        percentile=92.5,
        price=82000.0,
    )

    events = await db.get_extreme_events("BTC", "flow_1h", 30)
    assert len(events) == 1
    assert events[0].value == 47_700_000.0


async def test_record_respects_cooldown(db):
    import time

    tracker = ExtremeTracker(db)

    # ç¬¬ä¸€æ¬¡è®°å½•
    await tracker.record_event(
        symbol="BTC",
        dimension="flow_1h",
        window_days=30,
        value=47_700_000.0,
        percentile=92.5,
        price=82000.0,
    )

    # ç«‹å³å†æ¬¡è®°å½•ï¼ˆåº”è¢«å†·å´æœŸé˜»æ­¢ï¼‰
    await tracker.record_event(
        symbol="BTC",
        dimension="flow_1h",
        window_days=30,
        value=50_000_000.0,
        percentile=95.0,
        price=82500.0,
    )

    events = await db.get_extreme_events("BTC", "flow_1h", 30)
    assert len(events) == 1  # åªæœ‰ä¸€æ¡è®°å½•


async def test_different_windows_independent_cooldown(db):
    tracker = ExtremeTracker(db)

    # 30d çª—å£è®°å½•
    await tracker.record_event(
        symbol="BTC",
        dimension="flow_1h",
        window_days=30,
        value=47_700_000.0,
        percentile=92.5,
        price=82000.0,
    )

    # 7d çª—å£è®°å½•ï¼ˆä¸å— 30d å†·å´å½±å“ï¼‰
    await tracker.record_event(
        symbol="BTC",
        dimension="flow_1h",
        window_days=7,
        value=47_700_000.0,
        percentile=95.0,
        price=82000.0,
    )

    events_30d = await db.get_extreme_events("BTC", "flow_1h", 30)
    events_7d = await db.get_extreme_events("BTC", "flow_1h", 7)
    assert len(events_30d) == 1
    assert len(events_7d) == 1
```

**Step 2: Run tests to verify they fail**

Run: `uv run pytest tests/aggregator/test_extreme_tracker.py -v`
Expected: FAIL with "No module named 'src.aggregator.extreme_tracker'"

**Step 3: Write implementation**

åˆ›å»º `src/aggregator/extreme_tracker.py`ï¼š

```python
# src/aggregator/extreme_tracker.py
import time

from src.aggregator.percentile import calculate_percentile_multi_window
from src.storage.database import Database
from src.storage.models import ExtremeEvent


class ExtremeTracker:
    """æç«¯äº‹ä»¶æ£€æµ‹ä¸è®°å½•"""

    def __init__(self, db: Database, cooldown_hours: int = 1):
        self.db = db
        self.cooldown_hours = cooldown_hours

    def detect_extremes(
        self,
        value: float,
        history: list[float],
        threshold: float = 90,
        windows: list[int] = [7, 30, 90],
    ) -> dict[str, float]:
        """
        æ£€æµ‹å“ªäº›çª—å£è¾¾åˆ°æç«¯å€¼

        Returns:
            {çª—å£å: ç™¾åˆ†ä½} åªåŒ…å« >= threshold çš„çª—å£
        """
        percentiles = calculate_percentile_multi_window(value, history, windows)
        return {
            k: v
            for k, v in percentiles.items()
            if v is not None and v >= threshold
        }

    async def record_event(
        self,
        symbol: str,
        dimension: str,
        window_days: int,
        value: float,
        percentile: float,
        price: float,
    ) -> int | None:
        """
        è®°å½•æç«¯äº‹ä»¶

        Returns:
            äº‹ä»¶ IDï¼Œå¦‚æœåœ¨å†·å´æœŸå†…åˆ™è¿”å› None
        """
        # æ£€æŸ¥å†·å´æœŸ
        in_cooldown = await self.db.is_in_cooldown(
            symbol, dimension, window_days, self.cooldown_hours
        )
        if in_cooldown:
            return None

        event = ExtremeEvent(
            id=None,
            symbol=symbol,
            dimension=dimension,
            window_days=window_days,
            triggered_at=int(time.time() * 1000),
            value=value,
            percentile=percentile,
            price_at_trigger=price,
            price_4h=None,
            price_12h=None,
            price_24h=None,
            price_48h=None,
        )
        return await self.db.insert_extreme_event(event)
```

**Step 4: Run tests to verify they pass**

Run: `uv run pytest tests/aggregator/test_extreme_tracker.py -v`
Expected: All tests PASS

**Step 5: Commit**

```bash
git add src/aggregator/extreme_tracker.py tests/aggregator/test_extreme_tracker.py
git commit -m "feat: æ·»åŠ æç«¯äº‹ä»¶æ£€æµ‹ä¸è®°å½•"
```

---

## Task 5: å†å²ç»Ÿè®¡æŸ¥è¯¢

**Files:**
- Create: `src/aggregator/event_stats.py`
- Create: `tests/aggregator/test_event_stats.py`

**Step 1: Write the failing tests**

åˆ›å»º `tests/aggregator/test_event_stats.py`ï¼š

```python
# tests/aggregator/test_event_stats.py
import pytest

from src.aggregator.event_stats import EventStats


@pytest.fixture
async def db_with_events(tmp_path):
    from src.storage.database import Database
    from src.storage.models import ExtremeEvent

    db_path = tmp_path / "test.db"
    database = Database(str(db_path))
    await database.init()

    # æ’å…¥ 10 ä¸ªå®Œæ•´çš„å†å²äº‹ä»¶
    base_time = 1706000000000
    for i in range(10):
        event = ExtremeEvent(
            id=None,
            symbol="BTC",
            dimension="flow_1h",
            window_days=30,
            triggered_at=base_time + i * 3600 * 1000 * 24,  # æ¯å¤©ä¸€ä¸ª
            value=40_000_000.0 + i * 1_000_000,
            percentile=90.0 + i * 0.5,
            price_at_trigger=80000.0 + i * 100,
            price_4h=80000.0 + i * 100 + 50,  # ç•¥æ¶¨
            price_12h=80000.0 + i * 100 - 100,  # ç•¥è·Œ
            price_24h=80000.0 + i * 100 - 500 if i % 2 == 0 else 80000.0 + i * 100 + 300,
            price_48h=80000.0 + i * 100 - 200,
        )
        await database.insert_extreme_event(event)

    yield database
    await database.close()


async def test_get_stats_summary(db_with_events):
    stats = EventStats(db_with_events)

    summary = await stats.get_summary("BTC", "flow_1h", 30, limit=10)

    assert summary["count"] == 10
    assert "24h" in summary["stats"]
    assert "up_pct" in summary["stats"]["24h"]
    assert "down_pct" in summary["stats"]["24h"]
    assert "avg_change" in summary["stats"]["24h"]


async def test_get_stats_up_down_ratio(db_with_events):
    stats = EventStats(db_with_events)

    summary = await stats.get_summary("BTC", "flow_1h", 30)

    # 10 ä¸ªäº‹ä»¶ä¸­ï¼Œ5 ä¸ª 24h åæ¶¨ï¼ˆå¥‡æ•°ç´¢å¼•ï¼‰ï¼Œ5 ä¸ªè·Œï¼ˆå¶æ•°ç´¢å¼•ï¼‰
    assert summary["stats"]["24h"]["up_pct"] == 50.0
    assert summary["stats"]["24h"]["down_pct"] == 50.0


async def test_get_latest_event(db_with_events):
    stats = EventStats(db_with_events)

    latest = await stats.get_latest_event("BTC", "flow_1h", 30)

    assert latest is not None
    assert latest["triggered_at"] is not None
    assert latest["price_at_trigger"] is not None
    assert latest["change_24h"] is not None


async def test_stats_insufficient_data(tmp_path):
    from src.storage.database import Database

    db = Database(str(tmp_path / "test.db"))
    await db.init()

    stats = EventStats(db)
    summary = await stats.get_summary("BTC", "flow_1h", 30)

    assert summary["count"] == 0
    assert summary["stats"] == {}

    await db.close()
```

**Step 2: Run tests to verify they fail**

Run: `uv run pytest tests/aggregator/test_event_stats.py -v`
Expected: FAIL with "No module named 'src.aggregator.event_stats'"

**Step 3: Write implementation**

åˆ›å»º `src/aggregator/event_stats.py`ï¼š

```python
# src/aggregator/event_stats.py
from typing import Any

from src.storage.database import Database


class EventStats:
    """æç«¯äº‹ä»¶å†å²ç»Ÿè®¡"""

    def __init__(self, db: Database):
        self.db = db

    async def get_summary(
        self,
        symbol: str,
        dimension: str,
        window_days: int,
        limit: int = 20,
    ) -> dict[str, Any]:
        """
        è·å–å†å²äº‹ä»¶ç»Ÿè®¡æ‘˜è¦

        Returns:
            {
                "count": äº‹ä»¶æ•°é‡,
                "stats": {
                    "4h": {"up_pct": æ¶¨å æ¯”, "down_pct": è·Œå æ¯”, "avg_change": å¹³å‡æ¶¨è·Œå¹…},
                    "12h": {...},
                    "24h": {...},
                    "48h": {...},
                },
            }
        """
        events = await self.db.get_extreme_events(
            symbol, dimension, window_days, limit=limit, completed_only=True
        )

        if not events:
            return {"count": 0, "stats": {}}

        stats: dict[str, dict[str, float]] = {}
        for period, field in [
            ("4h", "price_4h"),
            ("12h", "price_12h"),
            ("24h", "price_24h"),
            ("48h", "price_48h"),
        ]:
            changes = []
            for e in events:
                price_after = getattr(e, field)
                if price_after is not None and e.price_at_trigger > 0:
                    change = (price_after - e.price_at_trigger) / e.price_at_trigger * 100
                    changes.append(change)

            if changes:
                up_count = sum(1 for c in changes if c > 0)
                down_count = sum(1 for c in changes if c < 0)
                total = len(changes)
                stats[period] = {
                    "up_pct": round(up_count / total * 100, 1),
                    "down_pct": round(down_count / total * 100, 1),
                    "avg_change": round(sum(changes) / total, 2),
                }

        return {"count": len(events), "stats": stats}

    async def get_latest_event(
        self,
        symbol: str,
        dimension: str,
        window_days: int,
    ) -> dict[str, Any] | None:
        """è·å–æœ€è¿‘ä¸€æ¬¡å®Œæ•´äº‹ä»¶"""
        events = await self.db.get_extreme_events(
            symbol, dimension, window_days, limit=1, completed_only=True
        )
        if not events:
            return None

        e = events[0]
        change_24h = None
        if e.price_24h is not None and e.price_at_trigger > 0:
            change_24h = round(
                (e.price_24h - e.price_at_trigger) / e.price_at_trigger * 100, 2
            )

        return {
            "triggered_at": e.triggered_at,
            "price_at_trigger": e.price_at_trigger,
            "price_24h": e.price_24h,
            "change_24h": change_24h,
        }
```

**Step 4: Run tests to verify they pass**

Run: `uv run pytest tests/aggregator/test_event_stats.py -v`
Expected: All tests PASS

**Step 5: Commit**

```bash
git add src/aggregator/event_stats.py tests/aggregator/test_event_stats.py
git commit -m "feat: æ·»åŠ æç«¯äº‹ä»¶å†å²ç»Ÿè®¡æŸ¥è¯¢"
```

---

## Task 6: æ ¼å¼åŒ–å†å²å‚è€ƒåŒºå—

**Files:**
- Modify: `src/notifier/formatter.py`
- Test: `tests/notifier/test_formatter.py`

**Step 1: Write the failing tests**

åœ¨ `tests/notifier/test_formatter.py` æœ«å°¾æ·»åŠ ï¼š

```python
def test_format_history_reference_block():
    from src.notifier.formatter import format_history_reference_block

    stats = {
        "7d": {
            "count": 20,
            "stats": {
                "24h": {"up_pct": 45.0, "down_pct": 55.0, "avg_change": -1.2},
            },
        },
        "30d": {
            "count": 15,
            "stats": {
                "24h": {"up_pct": 35.0, "down_pct": 65.0, "avg_change": -2.8},
            },
        },
    }
    latest = {
        "30d": {
            "triggered_at": 1706400000000,  # 2024-01-28
            "price_at_trigger": 82000.0,
            "change_24h": -4.8,
        }
    }

    result = format_history_reference_block(stats, latest)

    assert "7d P90+" in result
    assert "è¿‘20æ¬¡" in result
    assert "â†‘45%" in result
    assert "â†“55%" in result
    assert "30d P90+" in result
    assert "æœ€è¿‘(30d)" in result
    assert "-4.8%" in result


def test_format_history_reference_block_insufficient_data():
    from src.notifier.formatter import format_history_reference_block

    stats = {"7d": {"count": 3, "stats": {}}}  # å°‘äº 5 æ¬¡
    latest = {}

    result = format_history_reference_block(stats, latest)

    assert "æ•°æ®ç§¯ç´¯ä¸­" in result


def test_format_history_reference_block_empty():
    from src.notifier.formatter import format_history_reference_block

    result = format_history_reference_block({}, {})
    assert result == ""
```

**Step 2: Run tests to verify they fail**

Run: `uv run pytest tests/notifier/test_formatter.py::test_format_history_reference_block -v`
Expected: FAIL with "cannot import name 'format_history_reference_block'"

**Step 3: Write implementation**

åœ¨ `src/notifier/formatter.py` æœ«å°¾æ·»åŠ ï¼š

```python
def _format_timestamp_short(ts_ms: int) -> str:
    """æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸ºçŸ­æ ¼å¼ (M/D)"""
    from datetime import UTC, datetime

    dt = datetime.fromtimestamp(ts_ms / 1000, tz=UTC)
    return dt.strftime("%-m/%-d")


def format_history_reference_block(
    stats: dict[str, Any],
    latest: dict[str, Any],
    min_count: int = 5,
) -> str:
    """
    æ ¼å¼åŒ–å†å²å‚è€ƒåŒºå—

    Args:
        stats: {çª—å£: {count, stats}} ç»Ÿè®¡æ•°æ®
        latest: {çª—å£: {triggered_at, price_at_trigger, change_24h}} æœ€è¿‘äº‹ä»¶
        min_count: æœ€å°æ ·æœ¬æ•°

    Returns:
        æ ¼å¼åŒ–çš„å†å²å‚è€ƒæ–‡æœ¬
    """
    if not stats:
        return ""

    lines = ["  â”Œâ”€ ğŸ“œ å†å²å‚è€ƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"]

    has_valid_data = False
    for window in ["7d", "30d", "90d"]:
        if window not in stats:
            continue

        window_stats = stats[window]
        count = window_stats.get("count", 0)

        if count < min_count:
            lines.append(f"  â”‚ {window} P90+: æ•°æ®ç§¯ç´¯ä¸­ ({count}æ¬¡)")
            continue

        has_valid_data = True
        period_stats = window_stats.get("stats", {})

        lines.append(f"  â”‚ {window} P90+ (è¿‘{count}æ¬¡):")

        # æ˜¾ç¤º 24h ç»Ÿè®¡
        if "24h" in period_stats:
            s = period_stats["24h"]
            up = s["up_pct"]
            down = s["down_pct"]
            avg = s["avg_change"]
            sign = "+" if avg >= 0 else ""
            lines.append(f"  â”‚   24h: â†‘{up:.0f}% / â†“{down:.0f}%  å‡å€¼ {sign}{avg:.1f}%")

        lines.append("  â”‚")

    # æ˜¾ç¤ºæœ€è¿‘æ¡ˆä¾‹ï¼ˆä¼˜å…ˆè¾ƒé•¿çª—å£ï¼‰
    for window in ["90d", "30d", "7d"]:
        if window in latest and latest[window]:
            event = latest[window]
            date_str = _format_timestamp_short(event["triggered_at"])
            price = event["price_at_trigger"]
            change = event["change_24h"]
            if change is not None:
                sign = "+" if change >= 0 else ""
                lines.append(f"  â”‚ æœ€è¿‘({window}): {date_str} ${price:,.0f} â†’ 24h {sign}{change:.1f}%")
            break

    lines.append("  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

    if not has_valid_data and not any("æœ€è¿‘" in line for line in lines):
        return "  â”Œâ”€ ğŸ“œ å†å²å‚è€ƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  â”‚ æ•°æ®ç§¯ç´¯ä¸­\n  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"

    return "\n".join(lines)
```

**Step 4: Run tests to verify they pass**

Run: `uv run pytest tests/notifier/test_formatter.py -v -k history`
Expected: All history tests PASS

**Step 5: Commit**

```bash
git add src/notifier/formatter.py tests/notifier/test_formatter.py
git commit -m "feat: æ·»åŠ å†å²å‚è€ƒåŒºå—æ ¼å¼åŒ–"
```

---

## Task 7: ä»·æ ¼å›å¡«ä»»åŠ¡

**Files:**
- Create: `src/collector/event_backfiller.py`
- Create: `tests/collector/test_event_backfiller.py`

**Step 1: Write the failing tests**

åˆ›å»º `tests/collector/test_event_backfiller.py`ï¼š

```python
# tests/collector/test_event_backfiller.py
import time
from unittest.mock import AsyncMock, MagicMock

import pytest

from src.collector.event_backfiller import EventBackfiller


@pytest.fixture
async def db(tmp_path):
    from src.storage.database import Database

    db_path = tmp_path / "test.db"
    database = Database(str(db_path))
    await database.init()
    yield database
    await database.close()


@pytest.fixture
def mock_client():
    client = MagicMock()
    return client


async def test_backfill_determines_correct_fields(db, mock_client):
    from src.storage.models import ExtremeEvent

    now = int(time.time() * 1000)

    # æ’å…¥ä¸€ä¸ª 5 å°æ—¶å‰çš„äº‹ä»¶
    event = ExtremeEvent(
        id=None,
        symbol="BTC",
        dimension="flow_1h",
        window_days=30,
        triggered_at=now - 5 * 3600 * 1000,
        value=47_700_000.0,
        percentile=92.5,
        price_at_trigger=82000.0,
        price_4h=None,
        price_12h=None,
        price_24h=None,
        price_48h=None,
    )
    await db.insert_extreme_event(event)

    backfiller = EventBackfiller(db, mock_client)
    fields = backfiller._get_pending_fields(event, now)

    assert "price_4h" in fields
    assert "price_12h" not in fields


async def test_backfill_updates_price(db, mock_client):
    from src.storage.models import ExtremeEvent

    now = int(time.time() * 1000)

    event = ExtremeEvent(
        id=None,
        symbol="BTC",
        dimension="flow_1h",
        window_days=30,
        triggered_at=now - 5 * 3600 * 1000,
        value=47_700_000.0,
        percentile=92.5,
        price_at_trigger=82000.0,
        price_4h=None,
        price_12h=None,
        price_24h=None,
        price_48h=None,
    )
    event_id = await db.insert_extreme_event(event)

    # Mock get_klines è¿”å›ä»·æ ¼
    mock_kline = MagicMock()
    mock_kline.close = 82500.0
    mock_client.get_klines = AsyncMock(return_value=[mock_kline])

    backfiller = EventBackfiller(db, mock_client)
    await backfiller.backfill_one(event, now)

    # éªŒè¯ä»·æ ¼å·²æ›´æ–°
    events = await db.get_extreme_events("BTC", "flow_1h", 30)
    assert events[0].price_4h == 82500.0
```

**Step 2: Run tests to verify they fail**

Run: `uv run pytest tests/collector/test_event_backfiller.py -v`
Expected: FAIL with "No module named 'src.collector.event_backfiller'"

**Step 3: Write implementation**

åˆ›å»º `src/collector/event_backfiller.py`ï¼š

```python
# src/collector/event_backfiller.py
import logging
import time
from typing import TYPE_CHECKING

from src.storage.database import Database
from src.storage.models import ExtremeEvent

if TYPE_CHECKING:
    from src.client.binance import BinanceClient

logger = logging.getLogger(__name__)

# æ—¶é—´åç§»é‡ (ms)
BACKFILL_OFFSETS = {
    "price_4h": 4 * 3600 * 1000,
    "price_12h": 12 * 3600 * 1000,
    "price_24h": 24 * 3600 * 1000,
    "price_48h": 48 * 3600 * 1000,
}


class EventBackfiller:
    """æç«¯äº‹ä»¶åç»­ä»·æ ¼å›å¡«"""

    def __init__(self, db: Database, client: "BinanceClient"):
        self.db = db
        self.client = client

    def _get_pending_fields(
        self, event: ExtremeEvent, now_ms: int
    ) -> list[str]:
        """è·å–éœ€è¦å›å¡«çš„å­—æ®µ"""
        pending = []
        for field, offset in BACKFILL_OFFSETS.items():
            current_value = getattr(event, field)
            if current_value is None and event.triggered_at + offset <= now_ms:
                pending.append(field)
        return pending

    async def _get_price_at(self, symbol: str, target_time_ms: int) -> float | None:
        """è·å–æŒ‡å®šæ—¶é—´çš„ä»·æ ¼"""
        try:
            # å°†å†…éƒ¨ symbol (BTC) è½¬æ¢ä¸º Binance symbol (BTCUSDT)
            binance_symbol = f"{symbol}USDT"
            klines = await self.client.get_klines(
                binance_symbol, "1h", limit=1
            )
            if klines:
                return klines[0].close
            return None
        except Exception as e:
            logger.warning(f"Failed to get price for {symbol}: {e}")
            return None

    async def backfill_one(self, event: ExtremeEvent, now_ms: int | None = None) -> int:
        """
        å›å¡«å•ä¸ªäº‹ä»¶çš„åç»­ä»·æ ¼

        Returns:
            å›å¡«çš„å­—æ®µæ•°é‡
        """
        if now_ms is None:
            now_ms = int(time.time() * 1000)

        pending_fields = self._get_pending_fields(event, now_ms)
        if not pending_fields:
            return 0

        filled_count = 0
        for field in pending_fields:
            offset = BACKFILL_OFFSETS[field]
            target_time = event.triggered_at + offset
            price = await self._get_price_at(event.symbol, target_time)

            if price is not None and event.id is not None:
                await self.db.update_extreme_event_price(event.id, field, price)
                filled_count += 1
                logger.info(
                    f"Backfilled {field} for event {event.id}: {price}"
                )

        return filled_count

    async def run(self) -> int:
        """
        è¿è¡Œå›å¡«ä»»åŠ¡

        Returns:
            å›å¡«çš„æ€»å­—æ®µæ•°
        """
        events = await self.db.get_pending_backfill_events()
        total_filled = 0

        for event in events:
            filled = await self.backfill_one(event)
            total_filled += filled

        return total_filled
```

**Step 4: Run tests to verify they pass**

Run: `uv run pytest tests/collector/test_event_backfiller.py -v`
Expected: All tests PASS

**Step 5: Commit**

```bash
git add src/collector/event_backfiller.py tests/collector/test_event_backfiller.py
git commit -m "feat: æ·»åŠ æç«¯äº‹ä»¶ä»·æ ¼å›å¡«ä»»åŠ¡"
```

---

## Task 8: å†å²å›æµ‹è„šæœ¬æ¡†æ¶

**Files:**
- Create: `src/scripts/__init__.py`
- Create: `src/scripts/backfill_events.py`
- Create: `tests/scripts/__init__.py`
- Create: `tests/scripts/test_backfill_events.py`

**Step 1: Write the failing tests**

åˆ›å»º `tests/scripts/__init__.py`ï¼ˆç©ºæ–‡ä»¶ï¼‰å’Œ `tests/scripts/test_backfill_events.py`ï¼š

```python
# tests/scripts/test_backfill_events.py
import pytest


def test_parse_args():
    from src.scripts.backfill_events import parse_args

    args = parse_args(["--days", "365", "--symbol", "BTC"])
    assert args.days == 365
    assert args.symbol == "BTC"


def test_parse_args_defaults():
    from src.scripts.backfill_events import parse_args

    args = parse_args([])
    assert args.days == 365
    assert args.symbol is None  # é»˜è®¤å¤„ç†æ‰€æœ‰ symbol


async def test_calculate_historical_percentile():
    from src.scripts.backfill_events import calculate_historical_percentile

    # æ¨¡æ‹Ÿ 30 å¤©å†å²æ•°æ®
    history = [float(i) for i in range(1, 31)]  # 1-30
    current_idx = 25  # å½“å‰åœ¨ç¬¬ 26 å¤©

    # ä½¿ç”¨ 7 å¤©çª—å£
    result = calculate_historical_percentile(
        history, current_idx, value=28.0, window_days=7
    )

    # çª—å£æ•°æ®: 20-26ï¼Œvalue=28 è¶…è¿‡æ‰€æœ‰å€¼
    assert result == 100.0


async def test_calculate_historical_percentile_insufficient_data():
    from src.scripts.backfill_events import calculate_historical_percentile

    history = [1.0, 2.0, 3.0]
    result = calculate_historical_percentile(
        history, current_idx=2, value=2.5, window_days=7
    )
    assert result is None  # æ•°æ®ä¸è¶³
```

**Step 2: Run tests to verify they fail**

Run: `uv run pytest tests/scripts/test_backfill_events.py -v`
Expected: FAIL with "No module named 'src.scripts'"

**Step 3: Write implementation**

åˆ›å»º `src/scripts/__init__.py`ï¼ˆç©ºæ–‡ä»¶ï¼‰å’Œ `src/scripts/backfill_events.py`ï¼š

```python
# src/scripts/backfill_events.py
"""
å†å²æç«¯äº‹ä»¶å›æµ‹è„šæœ¬

ç”¨æ³•:
    uv run python -m src.scripts.backfill_events --days 365
    uv run python -m src.scripts.backfill_events --days 365 --symbol BTC
"""
import argparse
import asyncio
import logging
from typing import Sequence

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def parse_args(args: Sequence[str] | None = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="å›æµ‹å†å²æç«¯äº‹ä»¶")
    parser.add_argument(
        "--days",
        type=int,
        default=365,
        help="å›æµ‹å¤©æ•° (é»˜è®¤: 365)",
    )
    parser.add_argument(
        "--symbol",
        type=str,
        default=None,
        help="åªå›æµ‹æŒ‡å®š symbol (é»˜è®¤: å…¨éƒ¨)",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="åªæ‰“å°å°†è¦æ’å…¥çš„äº‹ä»¶ï¼Œä¸å®é™…å†™å…¥",
    )
    return parser.parse_args(args)


def calculate_historical_percentile(
    history: list[float],
    current_idx: int,
    value: float,
    window_days: int,
) -> float | None:
    """
    è®¡ç®—å†å²æŸä¸€æ—¶åˆ»çš„æ»šåŠ¨çª—å£ç™¾åˆ†ä½

    Args:
        history: å®Œæ•´å†å²æ•°æ®åˆ—è¡¨
        current_idx: å½“å‰æ—¶åˆ»åœ¨ history ä¸­çš„ç´¢å¼•
        value: å½“å‰å€¼
        window_days: çª—å£å¤§å°ï¼ˆå¤©ï¼‰

    Returns:
        ç™¾åˆ†ä½ï¼Œæ•°æ®ä¸è¶³æ—¶è¿”å› None
    """
    start_idx = max(0, current_idx - window_days + 1)
    window_data = history[start_idx:current_idx + 1]

    if len(window_data) < window_days:
        return None

    count_below = sum(1 for h in window_data if h < abs(value))
    return count_below / len(window_data) * 100


async def main() -> None:
    args = parse_args()
    logger.info(f"Starting backfill for {args.days} days")

    # TODO: å®ç°å®Œæ•´çš„å›æµ‹é€»è¾‘
    # 1. ä¸‹è½½å†å²æ•°æ®
    # 2. è®¡ç®—æ¯ä¸ªæ—¶é—´ç‚¹çš„ç™¾åˆ†ä½
    # 3. è¯†åˆ« P90+ äº‹ä»¶
    # 4. æ’å…¥ extreme_events è¡¨
    # 5. å›å¡«åç»­ä»·æ ¼

    logger.info("Backfill complete")


if __name__ == "__main__":
    asyncio.run(main())
```

**Step 4: Run tests to verify they pass**

Run: `uv run pytest tests/scripts/test_backfill_events.py -v`
Expected: All tests PASS

**Step 5: Commit**

```bash
git add src/scripts/__init__.py src/scripts/backfill_events.py tests/scripts/__init__.py tests/scripts/test_backfill_events.py
git commit -m "feat: æ·»åŠ å†å²å›æµ‹è„šæœ¬æ¡†æ¶"
```

---

## Task 9: é›†æˆåˆ°æŠ¥å‘Šç”Ÿæˆ

**Files:**
- Modify: `src/notifier/formatter.py` (format_insight_report)
- Test: `tests/notifier/test_formatter.py`

è¿™ä¸ªä»»åŠ¡éœ€è¦ä¿®æ”¹ `format_insight_report` å‡½æ•°ï¼Œåœ¨ P90+ ç»´åº¦ä¸‹æ–¹æ˜¾ç¤ºå†å²å‚è€ƒã€‚ç”±äºè¿™æ¶‰åŠåˆ°å¼‚æ­¥æ•°æ®åº“æŸ¥è¯¢ï¼Œéœ€è¦é‡æ„ä¸ºæ¥å—é¢„è®¡ç®—çš„å†å²æ•°æ®ã€‚

**Step 1: Write the failing test**

åœ¨ `tests/notifier/test_formatter.py` æ·»åŠ ï¼š

```python
def test_format_insight_report_with_history():
    from src.notifier.formatter import format_insight_report_with_history

    data = {
        "symbol": "BTC",
        "price": 82000.0,
        "price_change_1h": 0.5,
        "top_position_ratio": 1.8,
        "top_position_pct": 50.0,
        "top_position_pct_7d": 55.0,
        "top_position_pct_30d": 60.0,
        "top_position_pct_90d": 45.0,
        "top_position_change": 0.02,
        "global_account_ratio": 1.5,
        "global_account_pct": 78.0,
        "global_account_pct_7d": 80.0,
        "global_account_pct_30d": 75.0,
        "global_account_pct_90d": 70.0,
        "global_account_change": 0.01,
        "flow_1h": 47_700_000.0,
        "flow_1h_pct": 92.0,  # P90+ è§¦å‘
        "flow_1h_pct_7d": 95.0,
        "flow_1h_pct_30d": 92.0,
        "flow_1h_pct_90d": 70.0,
        "flow_binance": 47_700_000.0,
        "taker_ratio": 0.8,
        "taker_ratio_pct": 50.0,
        "taker_ratio_pct_7d": 50.0,
        "taker_ratio_pct_30d": 50.0,
        "taker_ratio_pct_90d": 50.0,
        "oi_value": 7_400_000_000.0,
        "oi_change_1h": 0.5,
        "oi_change_1h_pct": 60.0,
        "oi_change_1h_pct_7d": 60.0,
        "oi_change_1h_pct_30d": 55.0,
        "oi_change_1h_pct_90d": 50.0,
        "liq_1h_total": 500_000.0,
        "liq_long_ratio": 0.7,
        "funding_rate": 0.01,
        "funding_rate_pct": 50.0,
        "funding_rate_pct_7d": 50.0,
        "funding_rate_pct_30d": 50.0,
        "funding_rate_pct_90d": 50.0,
        "spot_perp_spread": 0.01,
        "spot_perp_spread_pct": 50.0,
        "spot_perp_spread_pct_7d": 50.0,
        "spot_perp_spread_pct_30d": 50.0,
        "spot_perp_spread_pct_90d": 50.0,
    }

    history_data = {
        "flow_1h": {
            "stats": {
                "7d": {"count": 20, "stats": {"24h": {"up_pct": 45.0, "down_pct": 55.0, "avg_change": -1.2}}},
                "30d": {"count": 15, "stats": {"24h": {"up_pct": 35.0, "down_pct": 65.0, "avg_change": -2.8}}},
            },
            "latest": {
                "30d": {"triggered_at": 1706400000000, "price_at_trigger": 82000.0, "change_24h": -4.8}
            },
        }
    }

    result = format_insight_report_with_history(data, history_data)

    assert "P95(7d) / P92(30d) / P70(90d)" in result
    assert "å†å²å‚è€ƒ" in result
    assert "7d P90+" in result
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest tests/notifier/test_formatter.py::test_format_insight_report_with_history -v`
Expected: FAIL with "cannot import name 'format_insight_report_with_history'"

**Step 3: Write implementation**

åœ¨ `src/notifier/formatter.py` æ·»åŠ æ–°å‡½æ•°ï¼ˆä¿ç•™åŸå‡½æ•°å…¼å®¹ï¼‰ï¼š

```python
def _format_multi_pct(pct_7d: float, pct_30d: float, pct_90d: float) -> str:
    """æ ¼å¼åŒ–ä¸‰çª—å£ç™¾åˆ†ä½"""
    return f"P{int(pct_7d)}(7d) / P{int(pct_30d)}(30d) / P{int(pct_90d)}(90d)"


def _has_extreme(pct_7d: float, pct_30d: float, pct_90d: float, threshold: float = 90) -> bool:
    """æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä¸€çª—å£è¾¾åˆ°æç«¯å€¼"""
    return pct_7d >= threshold or pct_30d >= threshold or pct_90d >= threshold


def format_insight_report_with_history(
    data: dict[str, Any],
    history_data: dict[str, Any] | None = None,
) -> str:
    """
    ç”Ÿæˆå¸¦å†å²å‚è€ƒçš„å¸‚åœºæ´å¯ŸæŠ¥å‘Š

    Args:
        data: å¸‚åœºæ•°æ®ï¼ˆåŒ…å« _pct_7d/_pct_30d/_pct_90d å­—æ®µï¼‰
        history_data: {ç»´åº¦: {stats, latest}} å†å²ç»Ÿè®¡æ•°æ®
    """
    now = datetime.now(UTC).strftime("%Y-%m-%d %H:%M UTC")
    history_data = history_data or {}

    # è½¬æ¢æ¯”ç‡ä¸ºç™¾åˆ†æ¯”
    top_long_pct = _ratio_to_pct(data["top_position_ratio"])
    top_short_pct = 100 - top_long_pct
    global_long_pct = _ratio_to_pct(data["global_account_ratio"])
    global_short_pct = 100 - global_long_pct
    taker_buy_pct = _ratio_to_pct(data["taker_ratio"])
    taker_sell_pct = 100 - taker_buy_pct

    # å˜åŒ–æ–¹å‘å’Œæè¿°
    top_dir = "â†‘" if data["top_position_change"] > 0 else "â†“"
    top_change_pct = abs(data["top_position_change"]) / max(data["top_position_ratio"], 0.01) * 100
    top_desc = _change_desc(data["top_position_change"])

    global_dir = "â†‘" if data["global_account_change"] > 0 else "â†“"
    global_change_pct = (
        abs(data["global_account_change"]) / max(data["global_account_ratio"], 0.01) * 100
    )
    global_desc = _change_desc(data["global_account_change"])

    # å¤§æˆ·æ•£æˆ·ä¸€è‡´æ€§åˆ¤æ–­
    both_long = top_long_pct > 50 and global_long_pct > 50
    both_short = top_long_pct < 50 and global_long_pct < 50
    if both_long:
        consensus = "å¤§æˆ·æ•£æˆ·ä¸€è‡´çœ‹å¤š"
    elif both_short:
        consensus = "å¤§æˆ·æ•£æˆ·ä¸€è‡´çœ‹ç©º"
    else:
        consensus = "å¤§æˆ·æ•£æˆ·å­˜åœ¨åˆ†æ­§"

    # èµ„é‡‘æµå‘
    flow_1h = _format_usd_signed(data["flow_1h"])
    flow_binance = _format_usd_signed(data["flow_binance"])
    flow_pct_str = _format_multi_pct(
        data.get("flow_1h_pct_7d", 50),
        data.get("flow_1h_pct_30d", 50),
        data.get("flow_1h_pct_90d", 50),
    )

    # Taker æè¿°
    if taker_buy_pct > 55:
        taker_desc = "ä¹°æ–¹ä¸»å¯¼"
    elif taker_buy_pct < 45:
        taker_desc = "å–æ–¹ä¸»å¯¼"
    else:
        taker_desc = "ä¹°å–å‡è¡¡"

    # OI è§£è¯»
    oi_interp = _oi_interpretation(data["oi_change_1h"], data["price_change_1h"])

    # çˆ†ä»“
    liq_long_pct = int(data["liq_long_ratio"] * 100)
    liq_short_pct = 100 - liq_long_pct
    if data["liq_long_ratio"] > 0.65:
        liq_desc = "å¤šå¤´æ‰¿å‹"
    elif data["liq_long_ratio"] < 0.35:
        liq_desc = "ç©ºå¤´æ‰¿å‹"
    else:
        liq_desc = "å¤šç©ºå‡è¡¡"

    # èµ„é‡‘è´¹ç‡æè¿°
    if data["funding_rate"] > 0.01:
        funding_desc = "å¤šå¤´ä»˜è´¹ï¼Œæƒ…ç»ªåå¤š"
    elif data["funding_rate"] < -0.01:
        funding_desc = "ç©ºå¤´ä»˜è´¹ï¼Œæƒ…ç»ªåç©º"
    else:
        funding_desc = "è´¹ç‡ä¸­æ€§"

    # æ„å»ºèµ„é‡‘æµå‘éƒ¨åˆ†ï¼ˆå¯èƒ½åŒ…å«å†å²å‚è€ƒï¼‰
    flow_section = f"""ğŸ’° èµ„é‡‘åŠ¨å‘ [å®æ—¶]

  ä¸»åŠ›å‡€æµå‘ (1h): {flow_1h}
    {flow_pct_str}
    Binance: {flow_binance}"""

    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ˜¾ç¤ºå†å²å‚è€ƒ
    if _has_extreme(
        data.get("flow_1h_pct_7d", 0),
        data.get("flow_1h_pct_30d", 0),
        data.get("flow_1h_pct_90d", 0),
    ):
        flow_history = history_data.get("flow_1h", {})
        if flow_history:
            history_block = format_history_reference_block(
                flow_history.get("stats", {}),
                flow_history.get("latest", {}),
            )
            if history_block:
                flow_section += "\n\n" + history_block

    # æ„å»ºæŠ¥å‘Š
    return f"""ğŸ“Š {data["symbol"]} å¸‚åœºæ´å¯Ÿ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’µ ${data["price"]:,.0f} ({data["price_change_1h"]:+.1f}% vs 1hå‰)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¯ å¤šç©ºå¯¹æ¯” [5mæ›´æ–°]

  å¤§æˆ·: {top_long_pct}% å¤š / {top_short_pct}% ç©º
        {top_dir}{top_change_pct:.0f}% vs 1hå‰ ({top_desc})

  æ•£æˆ·: {global_long_pct}% å¤š / {global_short_pct}% ç©º
        {global_dir}{global_change_pct:.0f}% vs 1hå‰ ({global_desc})

  â†’ {consensus}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{flow_section}

  Taker: {taker_buy_pct}% ä¹° / {taker_sell_pct}% å–
         {taker_desc}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ˆ æŒä»“ & çˆ†ä»“ [å®æ—¶]

  OI: {_format_usd(data["oi_value"])}
      {data["oi_change_1h"]:+.1f}% vs 1hå‰
      â†’ {oi_interp}

  çˆ†ä»“ (1h): {_format_usd(data["liq_1h_total"])}
      å¤š {liq_long_pct}% / ç©º {liq_short_pct}%
      â†’ {liq_desc}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š æƒ…ç»ªæŒ‡æ ‡

  èµ„é‡‘è´¹ç‡: {data["funding_rate"]:+.3f}%
            {funding_desc}

  åˆçº¦æº¢ä»·: {data["spot_perp_spread"]:+.2f}%

â° {now}"""
```

**Step 4: Run test to verify it passes**

Run: `uv run pytest tests/notifier/test_formatter.py::test_format_insight_report_with_history -v`
Expected: PASS

**Step 5: Commit**

```bash
git add src/notifier/formatter.py tests/notifier/test_formatter.py
git commit -m "feat: é›†æˆå†å²å‚è€ƒåˆ°å¸‚åœºæ´å¯ŸæŠ¥å‘Š"
```

---

## Task 10: è¿è¡Œå…¨éƒ¨æµ‹è¯•å¹¶éªŒè¯

**Step 1: Run all tests**

```bash
uv run pytest tests/ -v
```

Expected: All tests PASS

**Step 2: Run linting and type check**

```bash
uv run ruff check --fix . && uv run ruff format .
uv run mypy src/
```

Expected: No errors

**Step 3: Final commit**

```bash
git add .
git commit -m "chore: ä»£ç æ ¼å¼åŒ–å’Œç±»å‹æ£€æŸ¥é€šè¿‡"
```

---

## åç»­ä»»åŠ¡ï¼ˆæœªåŒ…å«åœ¨æœ¬è®¡åˆ’ä¸­ï¼‰

ä»¥ä¸‹ä»»åŠ¡éœ€è¦å•ç‹¬è§„åˆ’ï¼š

1. **å®Œå–„å›æµ‹è„šæœ¬** â€” å®ç°å®Œæ•´çš„å†å²æ•°æ®ä¸‹è½½å’Œç™¾åˆ†ä½è®¡ç®—é€»è¾‘
2. **é›†æˆåˆ°ä¸»æµç¨‹** â€” åœ¨ `main.py` ä¸­è°ƒç”¨ `EventBackfiller` å®šæ—¶ä»»åŠ¡
3. **ä¿®æ”¹ç°æœ‰æŠ¥å‘Šç”Ÿæˆ** â€” å°† `format_insight_report` è°ƒç”¨æ”¹ä¸º `format_insight_report_with_history`
4. **å…¶ä»–ç»´åº¦çš„å†å²å‚è€ƒ** â€” æ‰©å±•åˆ° OIã€èµ„é‡‘è´¹ç‡ç­‰ç»´åº¦
